{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecSys coursework 2020 template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python37564bitcec697e8df1e4b95a8b71588e12c06eb",
      "display_name": "Python 3.7.5 64-bit"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "THQFNe3zdt1f"
      },
      "source": [
        "# Assessed Coursework Template Notebook\n",
        "\n",
        "This is the template notebook for the RecSys(H) 2020 coursework. It deals with data preparation and evaluation only.\n",
        "\n",
        "Please note:\n",
        " - use H1 text headings for grouping together blocks of cells. You can then hide these while working on other blocks\n",
        " - leave the cell output visible when you submit the notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ww--_kl9-ndn"
      },
      "source": [
        "## Setup block\n",
        "\n",
        "Setup the data files, Python etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 7631k  100 7631k    0     0   466k      0  0:00:16  0:00:16 --:--:-- 1045k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 2366k  100 2366k    0     0  4218k      0 --:--:-- --:--:-- --:--:-- 4218k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 7581k  100 7581k    0     0  5506k      0  0:00:01  0:00:01 --:--:-- 5506k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 1895k  100 1895k    0     0  4501k      0 --:--:-- --:--:-- --:--:-- 4501k\n"
        }
      ],
      "source": [
        "!rm -rf ratings* books* to_read* test*\n",
        "\n",
        "!curl -o ratings.csv \"http://www.dcs.gla.ac.uk/~craigm/recsysH/coursework/final-ratings.csv\" \n",
        "!curl -o books.csv \"http://www.dcs.gla.ac.uk/~craigm/recsysH/coursework/final-books.csv\"\n",
        "!curl -o to_read.csv \"http://www.dcs.gla.ac.uk/~craigm/recsysH/coursework/final-to_read.csv\"\n",
        "!curl -o test.csv \"http://www.dcs.gla.ac.uk/~craigm/recsysH/coursework/final-test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Requirement already satisfied: spotlight from git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight in /usr/local/lib/python3.7/site-packages (1.0.7)\n"
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'spotlight.interactions'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3c3061a359b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 install git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspotlight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInteractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spotlight.interactions'"
          ]
        }
      ],
      "source": [
        "#Standard setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "!pip3 install git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight\n",
        "from spotlight.interactions import Interactions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RtJO0e0m-hun"
      },
      "source": [
        "# data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qKAb25iw1MYw"
      },
      "outputs": [],
      "source": [
        "#load in the csv files\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "books_df = pd.read_csv(\"books.csv\")\n",
        "to_read_df = pd.read_csv(\"to_read.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W6rqfn53OhDC"
      },
      "outputs": [],
      "source": [
        "#cut down the number of items and users\n",
        "counts=ratings_df[ratings_df[\"book_id\"] < 2000].groupby([\"book_id\"]).count().reset_index()\n",
        "valid_books=counts[counts[\"user_id\"] >= 10][[\"book_id\"]]\n",
        "\n",
        "books_df = books_df.merge(valid_books, on=\"book_id\")\n",
        "\n",
        "ratings_df = ratings_df[ratings_df[\"user_id\"] < 2000].merge(valid_books, on=\"book_id\")\n",
        "to_read_df = to_read_df[to_read_df[\"user_id\"] < 2000].merge(valid_books, on=\"book_id\")\n",
        "test = test[test[\"user_id\"] < 2000].merge(valid_books, on=\"book_id\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C7cgXhmYUXIn"
      },
      "source": [
        "Here we construct the Interactions objects from `ratings.csv`, `to_read.csv` and `test.csv`. We manually specify the num_users and num_items parameters to all Interaction objects, in case the test set differs from your training sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "15ClgJOdTTt1"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "\n",
        "from spotlight.cross_validation import random_train_test_split\n",
        "\n",
        "iid_map = defaultdict(count().__next__)\n",
        "\n",
        "\n",
        "rating_iids = np.array([iid_map[iid] for iid in ratings_df[\"book_id\"].values], dtype = np.int32)\n",
        "test_iids = np.array([iid_map[iid] for iid in test[\"book_id\"].values], dtype = np.int32)\n",
        "toread_iids = np.array([iid_map[iid] for iid in to_read_df[\"book_id\"].values], dtype = np.int32)\n",
        "\n",
        "\n",
        "uid_map = defaultdict(count().__next__)\n",
        "test_uids = np.array([uid_map[uid] for uid in test[\"user_id\"].values], dtype = np.int32)\n",
        "rating_uids = np.array([uid_map[uid] for uid in ratings_df[\"user_id\"].values], dtype = np.int32)\n",
        "toread_uids = np.array([uid_map[iid] for iid in to_read_df[\"user_id\"].values], dtype = np.int32)\n",
        "\n",
        "\n",
        "uid_rev_map = {v: k for k, v in uid_map.items()}\n",
        "iid_rev_map = {v: k for k, v in iid_map.items()}\n",
        "\n",
        "\n",
        "rating_dataset = Interactions(user_ids=rating_uids,\n",
        "                               item_ids=rating_iids,\n",
        "                               ratings=ratings_df[\"rating\"].values,\n",
        "                               num_users=len(uid_rev_map),\n",
        "                               num_items=len(iid_rev_map))\n",
        "\n",
        "toread_dataset = Interactions(user_ids=toread_uids,\n",
        "                               item_ids=toread_iids,\n",
        "                               num_users=len(uid_rev_map),\n",
        "                               num_items=len(iid_rev_map))\n",
        "\n",
        "test_dataset = Interactions(user_ids=test_uids,\n",
        "                               item_ids=test_iids,\n",
        "                               num_users=len(uid_rev_map),\n",
        "                               num_items=len(iid_rev_map))\n",
        "\n",
        "print(rating_dataset)\n",
        "print(toread_dataset)\n",
        "print(test_dataset)\n",
        "\n",
        "#here we define the validation set\n",
        "toread_dataset_train, validation = random_train_test_split(toread_dataset, random_state=np.random.seed(42))\n",
        "\n",
        "num_items = test_dataset.num_items\n",
        "num_users = test_dataset.num_users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kt4I2C5DTUL5"
      },
      "source": [
        "#Example code\n",
        "\n",
        "To evaluate soem of your hand-implemented recommender systems (e.g. Q1, Q4), you will need to instantiate objects that match the specification of a Spotlight model, which `mrr_score()` expects.\n",
        "\n",
        "\n",
        "Here is an example recommender object that returns 0 for each item, regardless of user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "s2eaxy_hakbC",
        "outputId": "35f634d1-66d1-4bc3-d0aa-beba617542ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "from spotlight.evaluation import mrr_score\n",
        "\n",
        "\n",
        "class dummymodel:\n",
        "  \n",
        "  def __init__(self, numitems):\n",
        "    self.predictions=np.zeros(numitems)\n",
        "  \n",
        "  #uid is the user we are requesting recommendations for;\n",
        "  #returns an array of scores, one for each item\n",
        "  def predict(self, uid):\n",
        "    #this model returns all zeros, regardless of userid\n",
        "    return( self.predictions )\n",
        "\n",
        "#lets evaluate how the effeciveness of dummymodel\n",
        "\n",
        "print(mrr_score(dummymodel(num_items), test_dataset, train=rating_dataset, k=100).mean())\n",
        "#as expected, a recommendation model that gives 0 scores for all items obtains a MRR score of 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "ZQTJOmS5dB3i",
        "outputId": "9f9ba8dd-922a-4284-c0ad-c921d581a10a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1999it [00:00, 2226.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#note that the latest copy of Craig's Spotlight displays a progress bar if you set verbose=True\n",
        "print(mrr_score(dummymodel(num_items), test_dataset, train=rating_dataset, k=100, verbose=True).mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SyvGgW_3ZjLV"
      },
      "source": [
        "#Q1\n",
        "\n",
        "You should create one block for each question"
      ]
    }
  ]
}